{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f9459d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "spark = SparkSession.builder.appName(\"PySpark-Practice\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a49378c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+\n",
      "|Name|Age|\n",
      "+----+---+\n",
      "|John| 28|\n",
      "|Jane| 33|\n",
      "|Mike| 45|\n",
      "+----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(\"John\", 28), (\"Jane\", 33), (\"Mike\", 45)]\n",
    "cols = [\"Name\", \"Age\"]\n",
    "df = spark.createDataFrame(data,cols)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cbd2588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|Name|\n",
      "+----+\n",
      "|John|\n",
      "|Jane|\n",
      "|Mike|\n",
      "+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"Name\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c724aa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(1,'Alice',3000),(2,'Bob',1500),(3,'Carol',4000)]\n",
    "cols=['id','name','salary']\n",
    "df = spark.createDataFrame(data,cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12a21d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+------+\n",
      "| id| name|salary|\n",
      "+---+-----+------+\n",
      "|  3|Carol|  4000|\n",
      "+---+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(col(\"salary\")>3000).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4d78d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+------+----+\n",
      "| id| name|salary|Flag|\n",
      "+---+-----+------+----+\n",
      "|  1|Alice|  3000|   Y|\n",
      "|  2|  Bob|  1500|   Y|\n",
      "|  3|Carol|  4000|   Y|\n",
      "+---+-----+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"Flag\", lit(\"Y\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96f5b1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[('US',100),('IN',200)]\n",
    "cols=['country','count']\n",
    "df = spark.createDataFrame(data,cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a597949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|country|total|\n",
      "+-------+-----+\n",
      "|     US|  100|\n",
      "|     IN|  200|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumnRenamed(\"count\",\"total\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "13a79545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "|  k|  v|\n",
      "+---+---+\n",
      "|  a|  1|\n",
      "|  b|  2|\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data=[('a',1),('b',2),('a',1)]\n",
    "cols=['k','v']\n",
    "df = spark.createDataFrame(data,cols)\n",
    "df.dropDuplicates().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cbbb6768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=[(1,),(2,),(3,)]\n",
    "cols=['num']\n",
    "df = spark.createDataFrame(data,cols)\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d2a2de45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|val|\n",
      "+---+\n",
      "|  x|\n",
      "|  y|\n",
      "|  x|\n",
      "+---+\n",
      "\n",
      "+---+\n",
      "|val|\n",
      "+---+\n",
      "|  x|\n",
      "|  y|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data=[('x',),( 'y',),('x',)]\n",
    "cols=['val']\n",
    "df = spark.createDataFrame(data,cols)\n",
    "df.show()\n",
    "df.select(\"val\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7306ca96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "|item|qty_sum|\n",
      "+----+-------+\n",
      "|   p|     15|\n",
      "|   q|     20|\n",
      "+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data=[('p',10),('q',20),('p',5)]\n",
    "cols=['item','qty']\n",
    "df = spark.createDataFrame(data,cols)\n",
    "df.groupBy(df.item).agg(sum(df.qty).alias(\"qty_sum\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "83fbb4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[('a',1),('b',2)]\n",
    "cols=['k','v']\n",
    "df = spark.createDataFrame(data,cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "04e14425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>v</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   k  v\n",
       "0  a  1\n",
       "1  b  2"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bc4e44e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "| id|score|\n",
      "+---+-----+\n",
      "|  p|    3|\n",
      "|  r|    2|\n",
      "|  q|    1|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data=[('p',3),('q',1),('r',2)]\n",
    "cols=['id','score']\n",
    "df = spark.createDataFrame(data,cols)\n",
    "df.orderBy(col('score').desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "082e5206",
   "metadata": {},
   "outputs": [],
   "source": [
    "left = [(1,'Alice'),(2,'Bob')]\n",
    "right = [(1,100),(3,300)]\n",
    "Lcols=['id','name']\n",
    "Rcols=['id','score']\n",
    "left_df = spark.createDataFrame(left, Lcols)\n",
    "right_df = spark.createDataFrame(right, Rcols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9cf88f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-----+\n",
      "| id| name|score|\n",
      "+---+-----+-----+\n",
      "|  1|Alice|  100|\n",
      "+---+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "left_df.join(right_df, \"id\", 'inner').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f3284604",
   "metadata": {},
   "outputs": [],
   "source": [
    "employees=[(1,'A'),(2,'B')]\n",
    "salaries=[(1,5000)]\n",
    "emps=spark.createDataFrame(employees,['id','name'])\n",
    "sal=spark.createDataFrame(salaries,['id','salary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "252b6c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+------+\n",
      "| id|name|salary|\n",
      "+---+----+------+\n",
      "|  1|   A|  5000|\n",
      "|  2|   B|  3000|\n",
      "+---+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emps.join(sal, \"id\", \"left\").na.fill({\"salary\":3000}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8465c5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[(1,['a','b']),(2,['c'])]\n",
    "cols=['id','tags']\n",
    "df=spark.createDataFrame(data,cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ce6b9d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+\n",
      "| id|expd_tag|\n",
      "+---+--------+\n",
      "|  1|       a|\n",
      "|  1|       b|\n",
      "|  2|       c|\n",
      "+---+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"id\", explode('tags').alias(\"expd_tag\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "38f8eb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[('John|Doe|30',),(('Jane|Smith|25',))]\n",
    "cols=['raw']\n",
    "df=spark.createDataFrame([('John|Doe|30',),('Jane|Smith|25',)],['raw'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1899ef2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|          raw|\n",
      "+-------------+\n",
      "|  John|Doe|30|\n",
      "|Jane|Smith|25|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e07bbca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+-----+---+\n",
      "|          raw|first| last|age|\n",
      "+-------------+-----+-----+---+\n",
      "|  John|Doe|30| John|  Doe| 30|\n",
      "|Jane|Smith|25| Jane|Smith| 25|\n",
      "+-------------+-----+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = df.withColumn(\"first\", split(df['raw'], '\\\\|').getItem(0)) \\\n",
    "        .withColumn(\"last\", split(df['raw'], '\\\\|').getItem(1)) \\\n",
    "        .withColumn(\"age\", split(df['raw'], '\\\\|').getItem(2))\n",
    "\n",
    "df2.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "45627a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[('A',100),('A',50),('B',200)]\n",
    "cols=['grp','val']\n",
    "df=spark.createDataFrame(data,cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "759f5d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+----------+\n",
      "|grp|val|row_number|\n",
      "+---+---+----------+\n",
      "|  A|100|         1|\n",
      "|  A| 50|         2|\n",
      "|  B|200|         1|\n",
      "+---+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "window = Window.partitionBy(df.grp).orderBy(df.val.desc())\n",
    "df.withColumn(\"row_number\", row_number().over(window)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9bdbd9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "items=[(1,'apple'),(2,'banana')]\n",
    "sales=[(1,5),(2,3),(1,2)]\n",
    "items_df=spark.createDataFrame(items,['id','item'])\n",
    "sales_df=spark.createDataFrame(sales,['id','qty'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "672e9afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+---+\n",
      "| id|  item|qty|\n",
      "+---+------+---+\n",
      "|  1| apple|  2|\n",
      "|  1| apple|  5|\n",
      "|  2|banana|  3|\n",
      "+---+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "items_df.join(broadcast(sales_df), \"id\", \"inner\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8208d574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+\n",
      "|  k|coll_list|\n",
      "+---+---------+\n",
      "|  x|   [1, 2]|\n",
      "|  y|      [3]|\n",
      "+---+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data=[('x',1),('x',2),('y',3)]\n",
    "cols=['k','v']\n",
    "df=spark.createDataFrame(data,cols)\n",
    "df.groupBy(df.k).agg(collect_list(df.v).alias(\"coll_list\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b7a304c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----+\n",
      "|  month|  A|   B|\n",
      "+-------+---+----+\n",
      "|2024-02|  8|NULL|\n",
      "|2024-01| 10|   5|\n",
      "+-------+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data=[('2024-01','A',10),('2024-01','B',5),('2024-02','A',8)]\n",
    "cols=['month','category','amt']\n",
    "df=spark.createDataFrame(data,cols)\n",
    "df.groupBy(\"month\").pivot(\"category\").agg(sum(df.amt)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8ae1983c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "|  a|  b|\n",
      "+---+---+\n",
      "|  1|  2|\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data=[('{\"a\":1,\"b\":2}',)]\n",
    "cols=['json_str']\n",
    "df=spark.createDataFrame(data,cols)\n",
    "schema = schema_of_json(df.select('json_str').first()[0])\n",
    "df2 = df.select(from_json('json_str', schema).alias('j')).select('j.*')\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1c51ec02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "| id|  k|\n",
      "+---+---+\n",
      "|  1|  x|\n",
      "|  2|  y|\n",
      "|  3|  z|\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a=[(1,'x'),(2,'y')]\n",
    "b=[(3,'z')]\n",
    "cols=['id','k']\n",
    "df1=spark.createDataFrame(a,cols)\n",
    "df2=spark.createDataFrame(b,cols)\n",
    "df1.union(df2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df28cb31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
